
Go 言語のプログラミングにおいて、goroutine 間で `chan` (チャンネル)を用いてデータを受け渡すのは日常茶飯事ですが、普通の `chan T` でデータを受け渡すよりも、長さ 1 の `make(chan struct{}, 1)` で「データの更新があった」情報のみ受け渡すことで多くのメリットを得ることができる、という記事です。

例えば、「ユーザーが更新操作を行った際に、あるページの表示を更新したい、ただし表示のための再計算処理はちょっと重い」といったよくあるケースで有用です。

## 手法の概要

詳細な説明は後ほどしますが、要約すると以下の通りです。

以下の 2 つのデータ構造を利用します:

- `make(chan struct{}, 1)` を用いて「データの更新があった」ことを goroutine 間でやりとりします
- 受け渡したいデータの本体は、別の場所に最新版のみを配置します
  - `sync.Mutex` 等で保護されたメモリ上でも、外部のストレージ上でもよいです

そして以下のロジックで処理します:

1. 更新側: 最新のデータをどこかに保存
2. 更新側: `make(chan struct{}, 1)` に空きがあるならば、空の構造体(`struct{}{}`)を送信 (「更新があった」ことの通知)
3. 受け手側 (非同期処理を行う goroutine): 以下を無限ループ実行:
  1. `chan` から `struct{}{}` を受信
  2. 最新のデータを取得し、処理を行う

更新の通知漏れが発生しないのか？といった点については後に触れます。

## メリット

以下すべての性質を保証することができます:

1. 受け手側の goroutine の処理が追いついていない時でも、送信側 goroutine がブロックされない
2. 最新版のデータのみを保持するため、メモリ・ストレージの消費量が(更新頻度に対して) `O(1)` である
3. 受け手側の goroutine のデータ処理中に複数回の更新が行われた場合でも、受け手側 goroutine で発生する処理は最小限に抑えられる (不必要に過去のバージョンデータを処理することがない)

特に、トラフィックに波・スパイクがありうるアプリケーションでこれらのメリットが活きてきます:

1. 送信側がブロックしない保証があるため、「API サーバーが詰まってしまいサービス全体に影響が出てしまった」といった問題を防げます
2. 「高速・高頻度にデータ更新された場合に、更新待ち行列に起因してメモリ・ストレージが枯渇しうる」というリスクを構造的に避けられます
3. 「後処理を行う goroutine (データの受け手側)が過去のデータでの処理ばかり行っており、なかなか最新版のデータでの処理が走らない」ことも防げます

## 制約

- データのすべてのバージョンを受け渡す・処理する必要がある場合には使えません
  - データが複数回更新された場合に、中間のバージョンをスキップしてよい・したい場合にのみ使える手法です
- 非同期処理対象ごとに `chan` を用意する必要があります
  - 例:「数千万件のページ *それぞれに対して* 、 *独立した* 再計算処理処理を走らせたい」という場合には、数千万件の `chan` 自体のオーバーヘッドが問題になります

### 普通の `chan T` と比べて何が良いか

受け渡したいデータそのものを `chan` に入れて受け渡す手法は有名ですが、その手法には以下の制約があります:

- Go の `chan` は固定長のキューであり、データの送信側(`chan` に入れる側)がブロッキングします
  - 大量の goroutine がブロックされてしまうと、それらの goroutine の参照するすべてのメモリや関係するリソース(処理に関わる TCP コネクション等)が解放されない点が問題になりえます
- `chan` には重複する要素をまとめる機能がない
  - 例えばデータがバージョン 1 から 100 まで一気に更新され、それをすべて `chan` で通知した場合、受け手側の goroutine は必ず 100 回処理することになります
  - せっかく goroutine によって非同期に処理しているにも関わらず、投入された更新 1 回 1 回を逐次処理してしまいます

「データの更新があった」ことだけを長さ 1 の `chan` を介して通知することで、これらの制約がどのように解決されるのかを以降で説明します。

## `make(chan struct{}, 1)` の動作原理

### コード例

....

なお実際には上記に加えて、graceful に終了するための `close` 処理などの実装も必要となることでしょう。


### 動作例

データの更新が素早く 5 回行われた(バージョン #1, #2, #3, #4, #5)状況を例示します:

....

なお、この例では更新が 5 回だけでしたが、例えば素早く 100 回更新された場合(バージョン #1, ..., #100 が一気に発生)であっても、送信側の goroutine はブロックされませんし、中間のバージョンすべて(#2, ..., #99)は同様にスキップされますし、メモリ・ストレージに保持するデータも常に一件だけです。


### データ整合性の保証

`chan struct{}` と別の場所でデータ本体を扱うことで 2 つのオブジェクトが登場していますが、本手法は以下のようにデータ整合性を保っています:

1. 送信側: 最新版データ本体の書込み *より後* に `chan struct{}` へ送信
2. 受信側: `chan struct{}` からの受信 *より後* にデータ本体を取得するため、`1.` または `1.` 以降に書き込まれたデータ本体が確実に読み取られる

ただし、当然ながらもデータ本体の書込み・取得それ自体には注意を要します:

- データ本体の読み書きは atomic である必要がある
  - Atomic: 新旧データの混ざった状態が読み取れてしまわない性質
  - Go のメモリ上にデータを持つのであれば、`sync.Mutex` ないし [atomic.Value + イミュータブルなデータ構造](https://pkg.go.dev/sync/atomic#Value) 等を利用しなければ保証されません
  - クラウドサービスのストレージ系のサービスであれば保証されていることが多いでしょう
- データ本体の読み書きにおいて read after write 一貫性が保証されている必要がある
  - Read after write 一貫性: 書込みより後に読込んだ際に、書込み以降のデータが読み取られる性質
  - Go 内部であれば [chan に関わるメモリモデルの仕様により保証対象です](https://go.dev/ref/mem#chan)
  - クラウドサービスではこの点はまちまちです。保証するサービス・しないサービスもあれば、性能などを代償にしつつ保証するオプションを提供しているサービスもあります。
    - [なお、以前の AWS S3 では read after write 保証が無く多くの人がハマっていましたが、今では保証されています](https://aws.amazon.com/jp/blogs/news/amazon-s3-update-strong-read-after-write-consistency/)


# アプリケーションの終了・クラッシュに対するケア

Go の `chan` はメモリ上の存在なので、アプリケーションの終了・クラッシュに関する考慮は(対象のデータの整合性の重要性次第ですが)必要です。

ただし、本稿で議論した局所的なデータ構造の周辺のみでデータ一貫性を保とうとするよりも、システム全体においてデータの修復・一貫性チェックを可能とするアーキテクチャの設計に取り組むことをおすすめします。そのようにすることで、開発・運用コストに対して得られるメリットがより大きく、また歪みも小さいシステムになることでしょう。

そのための手法は(特にマイクロサービス関連で)各所で言及されているものですが、例えば以下の設計パターンは例として挙げられるでしょう:

- [Saga](https://microservices.io/patterns/data/saga.html): 更新の進捗をコンポーネント・データのドメイン間で監視
  - 「大本のデータをバージョン #100 に更新したのに、非同期で更新される派生データがバージョン >= #100 になった通知が来ない」などを検知できれば、リトライといった対処ができる
- [Event Sourcing](https://www.google.com/search?q=event+sourcing+pattern): 大本になっている情報を履歴ベースのデータ構造にする
  - 大本になっている情報の更新履歴をアプリの終了・クラッシュより前の時点からリプレイすれば、結果的に `chan` への送信が再度行われる
- [Reconciliation](https://www.linkedin.com/pulse/cloud-mantra-reconciliation-patterns-tarun-sharma/): 定期的に既存のデータを突合することも考えられます
  - 処理の入力に用いたデータの現在のバージョンと、本手法を介して出力されたデータのバージョンが離れているデータを列挙すれば、 `chan` へ再度送信し更新できる
- そこまで重要でないデータ(キャッシュなど)であれば、そもそも気にしないのも選択肢でしょう
  - 同じデータの更新を伴うトラフィックが期待できる限り、そのうち再計算されて結局正しく更新されもします


# プロセス外部のストレージで同様のことはできるか？

原理的には Go の `make(chan struct{}, 1)` 以外でも同様の仕組みは実装しうるでしょう。プログラム外部のストレージ(Redis 等)で実装することすらも理論的には考えられます。

TODO: JVM のクラスとかにも軽く触れる

しかしながらも、Go の `chan` の性質によって助けられている側面には留意を要します。特に以下の性質を並立しようとすると意外と実装が複雑化になることも少なくないです:

- Go の `chan` は長さに上限を設定でき、その上限は必ず守られる
  - この点を妥協する場合、ストレージのサイジングや監視が代償になってきます
- Go の `chan` は「空きがあれば送信、なければ送信しない」という操作を atomic に行える
- Go の `chan` の通知は exactly-once である (通知漏れも通知しすぎも無い)
  - この点は at-least-once に妥協しても良いかもしれませんが、「通知が最大でどれだけ来るか」の保証が無ければ本手法のメリットのうち 1 つ(受け手側の負荷抑制の保証)が失われます
- Go の `chan` の操作は(通常の用途では)非常に高速かつ性能的に安定している
- Go の `chan` の操作の失敗を考慮する必要はない (失敗するような状況ではプログラム全体の動作自体が期待できない)

上記のひとつひとつの性質であれば何かしらの実装で満たすことも容易ですが、全てまたは大半を満たす実装は難易度・複雑度が高くなることでしょう。

Go の `chan` はインメモリであるため、先述の通りアプリケーションの終了・再起動に対するケアは必要になりえますが、それ以外の点においては便利にできています。
